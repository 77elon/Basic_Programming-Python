{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c88041e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 16:51:22.959397: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train_in = np.genfromtxt('data.in')\n",
    "x_train, y_train = train_in[:, :-1], train_in[:, -1]\n",
    "\n",
    "#generate some data distributed randomly\n",
    "n = 10000\n",
    "\n",
    "# #variables we will be solving for\n",
    "\n",
    "phi_1 = tf.Variable(3, trainable = True, dtype = tf.float32)\n",
    "c_1 = tf.Variable(0.5, trainable = True, dtype = tf.float32)\n",
    "phi_2 = tf.Variable(3.4, trainable = True, dtype = tf.float32)\n",
    "c_2 = tf.Variable(0.175, trainable = True, dtype = tf.float32)\n",
    "phi_3 = tf.Variable(5.5, trainable = True, dtype = tf.float32)\n",
    "c_3 = tf.Variable(0.008, trainable = True, dtype = tf.float32)\n",
    "\n",
    "#define loss\n",
    "def loss(phi_1, phi_2, phi_3, c_1, c_2, c_3):\n",
    "    rmse = tf.sqrt(tf.reduce_mean(tf.square( y_train - c_1*x_train**phi_1 + c_2*x_train**phi_2 + c_3*x_train**phi_3)))\n",
    "    return rmse\n",
    "\n",
    "#learning rate\n",
    "lr = 0.005\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(lr)\n",
    "\n",
    "trainable_variables = [phi_1, phi_2, phi_3, c_1, c_2, c_3]\n",
    "\n",
    "#epochs\n",
    "epochs = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ac81af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(epochs):\n",
    "    with tf.GradientTape() as tp:\n",
    "        loss_fn = loss(phi_1, phi_2, phi_3, c_1, c_2, c_3)\n",
    "    \n",
    "    #list of gradients for the current gradient tape\n",
    "    gradients = tp.gradient(loss_fn, trainable_variables)\n",
    "    #do the gradient descent\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78751d89-3658-4bae-b71a-a81d1d11848b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecc94a84cec4e59265442ba89994077d25c8bad7b5dbac8793171efaff97d6ad"
  },
  "kernelspec": {
   "display_name": "tensorflow-cpu",
   "language": "python",
   "name": "tensorflow-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
